[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "1st Attempt at Analysing World Data\n\n\n\n\n\n\n\nR\n\n\nData Analysis\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2023\n\n\nMP Rogers\n\n\n\n\n\n\n  \n\n\n\n\nMy Summer Seaweed Project\n\n\n\n\n\n\n\nMarine Biology\n\n\nSeaweed\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2023\n\n\nMP Rogers\n\n\n\n\n\n\n  \n\n\n\n\nStudents Performance Analysis\n\n\n\n\n\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 6, 2023\n\n\nMatthew-Pierre Rogers\n\n\n\n\n\n\n  \n\n\n\n\nTrip to Bowden\n\n\n\n\n\n\n\nMarine Biology\n\n\nKee Farms\n\n\nSeaweed\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nMP Rogers\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nMP Rogers\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sun and Sea",
    "section": "",
    "text": "Welcome to Sun and Sea, a blog where I talk about my experiences as a Jamaican marine biologist, and chronicle bits of my story as it unfolds."
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html",
    "href": "posts/Student Analysis/Student Performance Document.html",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "It’s been a while since I’ve sat down to practice using R and looking through data. So this is a chance for me to shake the rust off. I’m trying to write this summary as I go through the process to document my thoughts.\nI started heading over to Kaggle and looked for any dataset I found interesting, I shortlisted a few and this one made the cut.\nWithout further ado, let my load my trusty packages and get started.\n\nlibrary(tidyverse)\nlibrary(plotly)\n\n\n\nFirst I’ll bring in the data.\n\ndataset&lt;-read.csv(\"StudentsPerformance.csv\")\nglimpse(dataset)\n\nRows: 1,000\nColumns: 8\n$ gender                      &lt;chr&gt; \"female\", \"female\", \"female\", \"male\", \"mal…\n$ race.ethnicity              &lt;chr&gt; \"group B\", \"group C\", \"group B\", \"group A\"…\n$ parental.level.of.education &lt;chr&gt; \"bachelor's degree\", \"some college\", \"mast…\n$ lunch                       &lt;chr&gt; \"standard\", \"standard\", \"standard\", \"free/…\n$ test.preparation.course     &lt;chr&gt; \"none\", \"completed\", \"none\", \"none\", \"none…\n$ math.score                  &lt;int&gt; 72, 69, 90, 47, 76, 71, 88, 40, 64, 38, 58…\n$ reading.score               &lt;int&gt; 72, 90, 95, 57, 78, 83, 95, 43, 64, 60, 54…\n$ writing.score               &lt;int&gt; 74, 88, 93, 44, 75, 78, 92, 39, 67, 50, 52…\n\n\nAlrighty. So we have 1000 rows, an OK size. We have a field for Race, parental education level, lunch, whether they took a test preparation course, and then their math, reading and writing scores. I notice they have placeholders for the race field, likely to reduce any bias. Its a good move.\nA few questions jump out at me:\n\nDo the different genders score differently?\nDo different Races score differently.\nDoes taking the test prep course make a difference?\nAre Reading and Writing Scores more closely related than Math?\n\nOf these, I’m actually most curious about the last one, so let me work through them all.\n\n\n\nThere should be a couple ways to do this. We can carry out a 2 sample t-test.\n\ndataset&lt;- dataset |&gt; mutate( mean.score = (reading.score + writing.score + math.score)/3)\ngender.t.test&lt;-t.test(mean.score ~ gender, data = dataset, var.equal = FALSE)\nprint(gender.t.test)\n\n\n    Welch Two Sample t-test\n\ndata:  mean.score by gender\nt = 4.1789, df = 997.85, p-value = 3.186e-05\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n 1.979515 5.484516\nsample estimates:\nmean in group female   mean in group male \n            69.56950             65.83748 \n\n\nAccording to this, the female mean score is higher than the male mean score. The difference is statistically significant.\nI could also do an Analysis of Variance (ANOVA)\n\ngender.anova&lt;-aov(mean.score ~ gender, data = dataset)\nprint(summary(gender.anova))\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ngender        1   3477    3477   17.39 3.31e-05 ***\nResiduals   998 199591     200                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBoth agree, there a statistically significant difference between the mean score of the male and female students. The p-value, or chance that these results are due to chance is WAY less than 5%. At this sample size, I’d put some stock behind it.\nIn all honesty, I’d love to go through by Math, Reading and Writing to see if one particular subject has a bigger impact than the others.\n\n\n\nThe next one is a touchy topic. Thankfully the racial groups are designated with identifiers. I havent checked for the Key at the time of writing. A similar test can be be done. in this case an ANOVA is used to test the impact of race.\n\nrace.anova&lt;-aov(mean.score ~ race.ethnicity, data = dataset)\nprint(summary(race.anova))\n\n                Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nrace.ethnicity   4   7164  1790.9   9.096 3.23e-07 ***\nResiduals      995 195904   196.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOnce again the results are statistically significant. Now I could do something boring and bring up the mean mean score for each group like so:\n\nd&lt;-dataset |&gt; group_by(race.ethnicity) |&gt; summarise(race.mean = mean(mean.score))\nprint(d)\n\n# A tibble: 5 × 2\n  race.ethnicity race.mean\n  &lt;chr&gt;              &lt;dbl&gt;\n1 group A             63.0\n2 group B             65.5\n3 group C             67.1\n4 group D             69.2\n5 group E             72.8\n\n\nBut I find it may be better to do this graphically. there’s different ways to do this, but box plots are a good way to go. This plot shows the means of each racial group, but also an idea of how widely spread the scores are for each. For example, it lets you know that Race D has the second highest mean test score, but also that scores in thus race are the closest together, with less variation/spread.\n\n\n\n\n\n\n\n\nThe test prep course follows a similar analysis. The reason being that, for the purpose of this exercise, race, gender and whether the student did a test prep course are categorical variables. Students neatly fall into discrete groups.\nIn fact lets approach this one a little differently. Lets look at it graphically first. A lot of times thats better for intuition.\n\ntest.score.scatter&lt;-dataset |&gt; ggplot(mapping = aes(x = test.preparation.course, y = mean.score, fill = test.preparation.course))+\n  geom_violin(alpha= 0.8, show.legend = FALSE)+\n  stat_summary(fun = \"mean\", geom = \"crossbar\", color = \"black\", width = 0.7)+\n  labs(title = \"Mean test scores of students\")+\n  xlab(\"Did they complete the test prep course?\")+\n  ylab(\"Mean Test Score\")\ntest.score.scatter\n\n\n\n\nFrom looking, you can already get a sense that those who did the prep course generally did better. More of those students had higher scores. The lower performing students of the group also performed better than the low performers who didn’t do the course. If you are less comfortable eyeballing it (and checking is always good), we can calculate the p-value with an ANOVA as above.\n\ntest.prep.aov&lt;-aov(mean.score~test.preparation.course, data = dataset)\nprint(summary(test.prep.aov))\n\n                         Df Sum Sq Mean Sq F value Pr(&gt;F)    \ntest.preparation.course   1  13382   13382   70.41 &lt;2e-16 ***\nResiduals               998 189686     190                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn my head, i’m curious to know whether this test prep course is paid for or if there are other entrance requirements. At any rate: the difference is once again signficant.\n\n\n\nNow its time for the final question. This is actually the one i’m most curious about. Are Reading and writing scores more closesly related than math? To me, reading and writing feel like two sides of a coin. Math seems a little further away, so i’ll see what the data says.\n\nlibrary(ggcorrplot)\ntest.scores&lt;-dataset[,c(6:8)]\ncorr.matrix&lt;-cor(test.scores)\nprint(corr.matrix)\n\n              math.score reading.score writing.score\nmath.score     1.0000000     0.8175797     0.8026420\nreading.score  0.8175797     1.0000000     0.9545981\nwriting.score  0.8026420     0.9545981     1.0000000\n\n\nBut everyone loves graphs. So we’ll visualise it to tell a better story.\n\ncplot&lt;-ggcorrplot(corr.matrix, method = \"square\", type = \"lower\", lab = TRUE, title = \"Correlation matrix of student test scores\")\ncplot\n\n\n\n\nThe “redness” indicates closer relationships, as do the higher. To an extent I was right. All the scores are strongly correlated. In other words students who scored one way in say, math would tend to score similarly in reading and writing. However, reading and writing were more strongly correlated than either was to math. Which is about what I assumed\n\n\n\nThis was a good exercise to brush off the dust as far as getting back into my groove with R and analysing data. I genuinely think being able to understand statistics and data is important. While there are people who make this their whole career, I don’t think I’m there yet.\nI do think, career applications aside, I can get more use out of this. As a former lecturer of mine once repeated, “There’s lies, damn lies, and statistics” and a little understanding should help peel back some of those lies. For example, I could have hid a lot in mean score, especially if it turned out the scores weren’t highy correlated. Theres still more questions that these questions unearthed.\nBut even so, I think fostering a mindset of having questions, and knowing how to start finding the answers is important. Lets hope I stick to learning andimporving that aspect of my mind and skillset."
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html#bringing-in-the-data",
    "href": "posts/Student Analysis/Student Performance Document.html#bringing-in-the-data",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "First I’ll bring in the data.\n\ndataset&lt;-read.csv(\"StudentsPerformance.csv\")\nglimpse(dataset)\n\nRows: 1,000\nColumns: 8\n$ gender                      &lt;chr&gt; \"female\", \"female\", \"female\", \"male\", \"mal…\n$ race.ethnicity              &lt;chr&gt; \"group B\", \"group C\", \"group B\", \"group A\"…\n$ parental.level.of.education &lt;chr&gt; \"bachelor's degree\", \"some college\", \"mast…\n$ lunch                       &lt;chr&gt; \"standard\", \"standard\", \"standard\", \"free/…\n$ test.preparation.course     &lt;chr&gt; \"none\", \"completed\", \"none\", \"none\", \"none…\n$ math.score                  &lt;int&gt; 72, 69, 90, 47, 76, 71, 88, 40, 64, 38, 58…\n$ reading.score               &lt;int&gt; 72, 90, 95, 57, 78, 83, 95, 43, 64, 60, 54…\n$ writing.score               &lt;int&gt; 74, 88, 93, 44, 75, 78, 92, 39, 67, 50, 52…\n\n\nAlrighty. So we have 1000 rows, an OK size. We have a field for Race, parental education level, lunch, whether they took a test preparation course, and then their math, reading and writing scores. I notice they have placeholders for the race field, likely to reduce any bias. Its a good move.\nA few questions jump out at me:\n\nDo the different genders score differently?\nDo different Races score differently.\nDoes taking the test prep course make a difference?\nAre Reading and Writing Scores more closely related than Math?\n\nOf these, I’m actually most curious about the last one, so let me work through them all."
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html#do-the-genders-score-differently",
    "href": "posts/Student Analysis/Student Performance Document.html#do-the-genders-score-differently",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "There should be a couple ways to do this. We can carry out a 2 sample t-test.\n\ndataset&lt;- dataset |&gt; mutate( mean.score = (reading.score + writing.score + math.score)/3)\ngender.t.test&lt;-t.test(mean.score ~ gender, data = dataset, var.equal = FALSE)\nprint(gender.t.test)\n\n\n    Welch Two Sample t-test\n\ndata:  mean.score by gender\nt = 4.1789, df = 997.85, p-value = 3.186e-05\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n 1.979515 5.484516\nsample estimates:\nmean in group female   mean in group male \n            69.56950             65.83748 \n\n\nAccording to this, the female mean score is higher than the male mean score. The difference is statistically significant.\nI could also do an Analysis of Variance (ANOVA)\n\ngender.anova&lt;-aov(mean.score ~ gender, data = dataset)\nprint(summary(gender.anova))\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ngender        1   3477    3477   17.39 3.31e-05 ***\nResiduals   998 199591     200                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBoth agree, there a statistically significant difference between the mean score of the male and female students. The p-value, or chance that these results are due to chance is WAY less than 5%. At this sample size, I’d put some stock behind it.\nIn all honesty, I’d love to go through by Math, Reading and Writing to see if one particular subject has a bigger impact than the others."
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html#does-race-make-a-difference",
    "href": "posts/Student Analysis/Student Performance Document.html#does-race-make-a-difference",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "The next one is a touchy topic. Thankfully the racial groups are designated with identifiers. I havent checked for the Key at the time of writing. A similar test can be be done. in this case an ANOVA is used to test the impact of race.\n\nrace.anova&lt;-aov(mean.score ~ race.ethnicity, data = dataset)\nprint(summary(race.anova))\n\n                Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nrace.ethnicity   4   7164  1790.9   9.096 3.23e-07 ***\nResiduals      995 195904   196.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOnce again the results are statistically significant. Now I could do something boring and bring up the mean mean score for each group like so:\n\nd&lt;-dataset |&gt; group_by(race.ethnicity) |&gt; summarise(race.mean = mean(mean.score))\nprint(d)\n\n# A tibble: 5 × 2\n  race.ethnicity race.mean\n  &lt;chr&gt;              &lt;dbl&gt;\n1 group A             63.0\n2 group B             65.5\n3 group C             67.1\n4 group D             69.2\n5 group E             72.8\n\n\nBut I find it may be better to do this graphically. there’s different ways to do this, but box plots are a good way to go. This plot shows the means of each racial group, but also an idea of how widely spread the scores are for each. For example, it lets you know that Race D has the second highest mean test score, but also that scores in thus race are the closest together, with less variation/spread."
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html#test-prep-course",
    "href": "posts/Student Analysis/Student Performance Document.html#test-prep-course",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "The test prep course follows a similar analysis. The reason being that, for the purpose of this exercise, race, gender and whether the student did a test prep course are categorical variables. Students neatly fall into discrete groups.\nIn fact lets approach this one a little differently. Lets look at it graphically first. A lot of times thats better for intuition.\n\ntest.score.scatter&lt;-dataset |&gt; ggplot(mapping = aes(x = test.preparation.course, y = mean.score, fill = test.preparation.course))+\n  geom_violin(alpha= 0.8, show.legend = FALSE)+\n  stat_summary(fun = \"mean\", geom = \"crossbar\", color = \"black\", width = 0.7)+\n  labs(title = \"Mean test scores of students\")+\n  xlab(\"Did they complete the test prep course?\")+\n  ylab(\"Mean Test Score\")\ntest.score.scatter\n\n\n\n\nFrom looking, you can already get a sense that those who did the prep course generally did better. More of those students had higher scores. The lower performing students of the group also performed better than the low performers who didn’t do the course. If you are less comfortable eyeballing it (and checking is always good), we can calculate the p-value with an ANOVA as above.\n\ntest.prep.aov&lt;-aov(mean.score~test.preparation.course, data = dataset)\nprint(summary(test.prep.aov))\n\n                         Df Sum Sq Mean Sq F value Pr(&gt;F)    \ntest.preparation.course   1  13382   13382   70.41 &lt;2e-16 ***\nResiduals               998 189686     190                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn my head, i’m curious to know whether this test prep course is paid for or if there are other entrance requirements. At any rate: the difference is once again signficant."
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html#reading-and-writing",
    "href": "posts/Student Analysis/Student Performance Document.html#reading-and-writing",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "Now its time for the final question. This is actually the one i’m most curious about. Are Reading and writing scores more closesly related than math? To me, reading and writing feel like two sides of a coin. Math seems a little further away, so i’ll see what the data says.\n\nlibrary(ggcorrplot)\ntest.scores&lt;-dataset[,c(6:8)]\ncorr.matrix&lt;-cor(test.scores)\nprint(corr.matrix)\n\n              math.score reading.score writing.score\nmath.score     1.0000000     0.8175797     0.8026420\nreading.score  0.8175797     1.0000000     0.9545981\nwriting.score  0.8026420     0.9545981     1.0000000\n\n\nBut everyone loves graphs. So we’ll visualise it to tell a better story.\n\ncplot&lt;-ggcorrplot(corr.matrix, method = \"square\", type = \"lower\", lab = TRUE, title = \"Correlation matrix of student test scores\")\ncplot\n\n\n\n\nThe “redness” indicates closer relationships, as do the higher. To an extent I was right. All the scores are strongly correlated. In other words students who scored one way in say, math would tend to score similarly in reading and writing. However, reading and writing were more strongly correlated than either was to math. Which is about what I assumed"
  },
  {
    "objectID": "posts/Student Analysis/Student Performance Document.html#final-thoughts",
    "href": "posts/Student Analysis/Student Performance Document.html#final-thoughts",
    "title": "Students Performance Analysis",
    "section": "",
    "text": "This was a good exercise to brush off the dust as far as getting back into my groove with R and analysing data. I genuinely think being able to understand statistics and data is important. While there are people who make this their whole career, I don’t think I’m there yet.\nI do think, career applications aside, I can get more use out of this. As a former lecturer of mine once repeated, “There’s lies, damn lies, and statistics” and a little understanding should help peel back some of those lies. For example, I could have hid a lot in mean score, especially if it turned out the scores weren’t highy correlated. Theres still more questions that these questions unearthed.\nBut even so, I think fostering a mindset of having questions, and knowing how to start finding the answers is important. Lets hope I stick to learning andimporving that aspect of my mind and skillset."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Get to Know Me\nMy name is Matthew-Pierre Rogers, but you’ll see MP around this site. I’m a young Jamaican, a marine biologist and a lover of the ocean.\n\n\n\nMe on a Dive\n\n\nI graduated recently(2022) from the University of the West Indies and now, I am seeing how I can make the best use of my marine biology to support, not just me, but the seas of Jamaica and the wider Caribbean. Marine Biology is a pretty broad field. In fact, I think a good idea for one my first posts is on just how diverse life in the sea is, with some of my favourite organisms.\nCurrently, I work with Kee Farms, a start-up bringing seaweed farming and mariculture in general to Jamaica and the Caribbean. You’ll be hearing more about my work and adventures there as I keep posting. I’m also grateful to be accepted for an internship at the Discovery Bay Marine Lab, which will give me an opportunity to work under more seasoned marine scientists, help out with research, and tighten up my own scuba and scientific skills.\n\n\nAbout This Site\nThis is where I get to share my marine biology stories and fun facts, as well as any analysis I find cool. I find that a lot of science types have trouble communicating exactly what we do, and just how cool it is. This is my attempt to get better at that, and tell some fun stories along the way. In that sense it’s both communication, and documentation. Welcome. Glad to have you along for the ride"
  },
  {
    "objectID": "docs/posts/Trip to Bowden/Trip to Bowden.html",
    "href": "docs/posts/Trip to Bowden/Trip to Bowden.html",
    "title": "Trip to Bowden",
    "section": "",
    "text": "So about a week ago, on February 11, 2023, I went on a dive trip with my team at Kee Farms. Here is a little bit of that story."
  },
  {
    "objectID": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-goals",
    "href": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-goals",
    "title": "Trip to Bowden",
    "section": "The Goals",
    "text": "The Goals\nAt Kee Farms, to put it simply, we grow marine products like seaweed. However, we are still in the learning process. Our first batch of seaweed was depleted. So we needed a new starting crop to start growing. This meant taking a team out into the wild to find and gather some wild seaweed. Ideally, we wanted the same species of seaweed we had been growing before. Right now, we are focusing on a red seaweed known as Gracilaria . Gracilaria is a useful and popular red seaweed. Different species of Gracilaria are grown in other parts of the world. Here in Jamaica, we call it “irish moss” and traditionally for it, but our company is among the first to farm it. Here you can see some of the Gracilaria from our first round of collection dives. This specific species is called Gracilaria domingensis.\n\n\n\nSome of the Irish Moss in hand\n\n\n\n\n\nSome Irish Moss from our first trip to White Horses"
  },
  {
    "objectID": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-start",
    "href": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-start",
    "title": "Trip to Bowden",
    "section": "The Start",
    "text": "The Start\nI’ll be honest. I had mixed feelings about this trip to start. Our first batch of seaweed came from a site named White Horses in St. Thomas. Its called that because the waves crashing look like..well..white horses. In other words, the water gets pretty rough. The roads to and from that site are pretty rough in their own right. The first trip was pretty rough in its own right. The second trip to White Horses was even worse. That time, the other divers and I had gotten into a mess. We collected no seaweed and almost got ourselves seriously hurt. It was a textbook case of horrible conditions. Visibility was less than three feet, surge was rough and the current pushed us towards rocks with some serious force.\n\n\n\n\n\nBut as the leader for the last dive, my team and I made sure we analyzed our loss(after a beer) ad figured out what we could do better. One of the major steps was to reach our dive site early, before the water picked up for the day. We had tried to reach early on the previous trip, but due to circumstances, we didn’t reach until 1pm, when the sea was already rough.\nSo this time, we left out at 4:30 am. So after a wonderful 4 hours of sleep, we got driving. A contact had advised us of a new dive site. The drive was long, but they had done some paving on the roads. It wasn’t great, but I could see the improvement. We got to see some nice views on the ride down. Jamaica, especially the parish of Portland, is a beautiful place. Especially if you’re like me and love the sea and sea views.\n\n\n\nSunrise in Portland Jamaica\n\n\nWe kept driving and arrived around 8am. And then after stretching our legs, we got to work."
  },
  {
    "objectID": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-collection",
    "href": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-collection",
    "title": "Trip to Bowden",
    "section": "The Collection",
    "text": "The Collection\nOnce we arrived, our guide led us out into the bay, we were expecting shallow water, maybe only 10, 20 feet, but to our surprise it was knee height. The sediment was muddy, and visibility was basically nothing(and yet somehow still better than white horses.) We could feel down and pull up the seaweed. It was another Gracilaria species, but we were more than happy to take it. We didn’t need our Scuba gear, so we set it to float at the surface. It helped keep our collection bags off the bottom as well. Then we went gathering up the irish moss. We talked and joked about crocs coming for us while we harvested. It had one of the divers so wound up she jumped at a fish, thinking it was a croc. Eventually the team, after a little more than an hour and a half, made our way back into shore.\nWe talked to some locals who told us how there was plenty of another kind of irish moss nearby and showed us the site. We loaded up our truck, and got moving.\n\n\n\nMe at the Bowden Bay, ready to gather some seaweed"
  },
  {
    "objectID": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-return",
    "href": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-return",
    "title": "Trip to Bowden",
    "section": "The Return",
    "text": "The Return\nThe ride back wasn’t bad. As always, I discussed what could have gone better with my team and what we’d do differently. There wasn’t a lot to change. It wasn’t exactly what we suspected, but it was a good trip."
  },
  {
    "objectID": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-afterwards",
    "href": "docs/posts/Trip to Bowden/Trip to Bowden.html#the-afterwards",
    "title": "Trip to Bowden",
    "section": "The Afterwards",
    "text": "The Afterwards\nWhen we reached back, we loaded in the seaweed to be sterilised. We try not to bring foreign diseases or organisms into the Bay we work at, Turtle Crawle Bay. We went to check on our oyster crops. We had been drying the little guys to clean off any other sea creatures growing on them. And finally we got out of the water.\nWe tried to rinse our scuba gear, as you always should. Only to find there was no freshwater. So someone working at our partners in the bay, took us to a little roadside waterfall to rinse off…which was also dry. He said he had one more option, and took us through a VERY out of the way path, to a stream where we could rinse our gear and ourselves. We had a little swim and rinse off, and started the drive home.\nAll credit for photos goes out to my team members who took them. In particular I’d love to big up Britney Williams."
  },
  {
    "objectID": "docs/posts/My Summer Seaweed Project/My Summer Seaweed Project.html",
    "href": "docs/posts/My Summer Seaweed Project/My Summer Seaweed Project.html",
    "title": "My Summer Seaweed Project",
    "section": "",
    "text": "Just a brief disclaimer: This article was originally published in August 2023 on my LinkedIn. I’ve copied it over and made a few edits to drop it on my blog.\nDuring my Internship at the Discovery Bay Marine Lab, I had the honour and opportunity to pursue a research project of my own, provided I kept up with my internship responsibilities. I chose to undertake a personal project, and chose one near and dear to my heart, Seaweed Cultivation.\nSeaweed aquaculture and mariculture are topics I believe hold a lot of promise for Jamaica and the wider Caribbean. Jamaica already uses seaweeds, collectively termed “irish moss” in a number of traditional foods and beverages. To date however, the seaweeds used have all been wild harvested. This runs the risk of depleting natural stock.\nCultivating these seaweeds would give more control, help produce more consistent supply, and provide income to coastal communities. There are also several other value-added products which can be created from seaweeds. If it catches on, seaweed farming can also help remove excess nutrients from the water and help ease pressure on the local marine environment. Other territories, namely in East Africa and Asia do cultivate seaweeds, but the practice is not established in Jamaica.\nI had been interested in the topic before, and took this opportunity to explore it. My supervisor and I identified the species of Irish Moss available as Euchuema cotonii. Over the course of my internship. I reviewed existing literature, built out a simple cultivation apparatus, seeded it with Irish Moss and tended it.\n\n\n\nMe with my DIY cultivation apparatus\n\n\nThis tending usually took the form of cleaning. Every Wednesday, I would go shake the silt and sand off my seaweed. Then I would weigh it and record the data. Normally, if I was in the water, which was often, I’d check and clean the seaweed then too.\n\n\n\nWeighing the seaweed to monitor growth\n\n\nAs a scientist, I believe in using data, quantifying results and making data driven decisions as much as possible. I recorded the growth, health and appearance of my seaweed crop. I analysed and visualised the results using R. I learned a lot being in the water tending to my seaweed. And as a reward, I got to be (as far as I’m aware) one of if not the first seaweed farmers of the 21st century in Jamaica.\n\n\n\nMe with the seaweed the day I planted it out on April 14, 2023\n\n\n\n\n\nMe and my friend Andrew lifting my seaweed on May 31, 2023\n\n\nFrom this you can easily see the crazy growth my crop managed to achieve. Eucheuma is cultivated around the world and known for its rapid growth, commnly said to triple in size in 6 weeks. My Eucheuma managed to match these figures. There’s a lot more detailed analysis that went into the report, but to put it simply:\n\n\n\nGraph Showing the mean mass of my samples over the experiment\n\n\nThe data and growth I recorded was more than encouraging, The possibility of cultivating seaweed in Jamaica and the wider Caribbean seems bright and hopeful. I personally intend to continue working at it, and establishing mariculture in Jamaica."
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html",
    "href": "docs/posts/1st World Data Analysis/WorldData.html",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "Here is another attempt at me trying to practice and get used to using R. I chose this one for a few reasons: One, I do have a passing interest in economics and development. As a Jamaican from a so called third world country/developing state, one of my big wishes is to see Jamaica and other Caribbean nations “develop” in a way that helps the citizens live better lives.\nAdditionally, depending on what we find in this dataset on countries around the world in 2023, I figure there may be some good insights to be gained. So its time to explore and see what we find.\nLet’s begin by importing the data:\n\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(plotly)\nlibrary(scales)\nlibrary(corrplot)\nlibrary(ggcorrplot)\ndataset&lt;-read.csv(\"world-data-2023.csv\")\n\nNow that the data has been imported, I’ll have a little look to see what I’m working with.\n\nglimpse(dataset)\n\nRows: 195\nColumns: 35\n$ Country                                   &lt;chr&gt; \"Afghanistan\", \"Albania\", \"A…\n$ Density..P.Km2.                           &lt;chr&gt; \"60\", \"105\", \"18\", \"164\", \"2…\n$ Abbreviation                              &lt;chr&gt; \"AF\", \"AL\", \"DZ\", \"AD\", \"AO\"…\n$ Agricultural.Land....                     &lt;chr&gt; \"58.10%\", \"43.10%\", \"17.40%\"…\n$ Land.Area.Km2.                            &lt;chr&gt; \"652,230\", \"28,748\", \"2,381,…\n$ Armed.Forces.size                         &lt;chr&gt; \"323,000\", \"9,000\", \"317,000…\n$ Birth.Rate                                &lt;dbl&gt; 32.49, 11.78, 24.28, 7.20, 4…\n$ Calling.Code                              &lt;int&gt; 93, 355, 213, 376, 244, 1, 5…\n$ Capital.Major.City                        &lt;chr&gt; \"Kabul\", \"Tirana\", \"Algiers\"…\n$ Co2.Emissions                             &lt;chr&gt; \"8,672\", \"4,536\", \"150,006\",…\n$ CPI                                       &lt;chr&gt; \"149.9\", \"119.05\", \"151.36\",…\n$ CPI.Change....                            &lt;chr&gt; \"2.30%\", \"1.40%\", \"2.00%\", \"…\n$ Currency.Code                             &lt;chr&gt; \"AFN\", \"ALL\", \"DZD\", \"EUR\", …\n$ Fertility.Rate                            &lt;dbl&gt; 4.47, 1.62, 3.02, 1.27, 5.52…\n$ Forested.Area....                         &lt;chr&gt; \"2.10%\", \"28.10%\", \"0.80%\", …\n$ Gasoline.Price                            &lt;chr&gt; \"$0.70 \", \"$1.36 \", \"$0.28 \"…\n$ GDP                                       &lt;chr&gt; \"$19,101,353,833 \", \"$15,278…\n$ Gross.primary.education.enrollment....    &lt;chr&gt; \"104.00%\", \"107.00%\", \"109.9…\n$ Gross.tertiary.education.enrollment....   &lt;chr&gt; \"9.70%\", \"55.00%\", \"51.40%\",…\n$ Infant.mortality                          &lt;dbl&gt; 47.9, 7.8, 20.1, 2.7, 51.6, …\n$ Largest.city                              &lt;chr&gt; \"Kabul\", \"Tirana\", \"Algiers\"…\n$ Life.expectancy                           &lt;dbl&gt; 64.5, 78.5, 76.7, NA, 60.8, …\n$ Maternal.mortality.ratio                  &lt;int&gt; 638, 15, 112, NA, 241, 42, 3…\n$ Minimum.wage                              &lt;chr&gt; \"$0.43 \", \"$1.12 \", \"$0.95 \"…\n$ Official.language                         &lt;chr&gt; \"Pashto\", \"Albanian\", \"Arabi…\n$ Out.of.pocket.health.expenditure          &lt;chr&gt; \"78.40%\", \"56.90%\", \"28.10%\"…\n$ Physicians.per.thousand                   &lt;dbl&gt; 0.28, 1.20, 1.72, 3.33, 0.21…\n$ Population                                &lt;chr&gt; \"38,041,754\", \"2,854,191\", \"…\n$ Population..Labor.force.participation.... &lt;chr&gt; \"48.90%\", \"55.70%\", \"41.20%\"…\n$ Tax.revenue....                           &lt;chr&gt; \"9.30%\", \"18.60%\", \"37.20%\",…\n$ Total.tax.rate                            &lt;chr&gt; \"71.40%\", \"36.60%\", \"66.10%\"…\n$ Unemployment.rate                         &lt;chr&gt; \"11.12%\", \"12.33%\", \"11.70%\"…\n$ Urban_population                          &lt;chr&gt; \"9,797,273\", \"1,747,593\", \"3…\n$ Latitude                                  &lt;dbl&gt; 33.939110, 41.153332, 28.033…\n$ Longitude                                 &lt;dbl&gt; 67.709953, 20.168331, 1.6596…\n\n\nThis shows a great deal. In this dataset, there are 195 rows or records. Each one represents an individual country. There are also 35 columns or fields. Each field represents a specific observation. The function in R also gives me the names and data types of these fields. Lots of the fields appear to be country demographics and general information. There’s a lot to be judged here.\nAnd from this I can see the first issue. A lot of these fields that I would expect to be numbers are formatted as characters or text. Its not an impossible problem to fix, but if it’s not dealt with, it will make doing any analysis annoying at best and impossible at worst.\n\n\nCleaning 35 columns now, saves me a lot of heartache in the future. I won’t show it all but here are some examples of how I could do that.\n\ndataset&lt;- dataset |&gt; mutate (GDP = GDP |&gt; str_remove_all(\"[$,]\") |&gt; as.numeric())\ndataset$Density..P.Km2.&lt;-as.numeric(dataset$Density..P.Km2.)\n\nThankfully, there are more efficient ways to work\n\nc.names&lt;-colnames(dataset)\ncols.to.format&lt;-c.names[-c(1,3, 9, 13, 21, 25)]\ncols.that.can.stay&lt;-c.names[c(1,3, 9, 13, 21, 25)]\ndataset&lt;-dataset |&gt; \n  mutate(across(.cols = cols.to.format,.fns = ~str_remove_all(.x, \"[$,%]\")|&gt; \n                  as.numeric()))\n\nWhat I’ve done above is to convert all the relevant character or text fields/columns into numbers so I can work with them.\n\n\n\nNow comes the brainstorming. There’s a lot of data here. A lot of the questions that come to mind have to do with GDP. GDP, the gross domestic product, is essentially the dollar value of all the “Stuff” bought and sold in a country. You could also look at it as the country’s income. It’s not a perfect measure, but it can be useful. At the very least it gives me some questions to ask.\nThe questions that pop out to me are:\n\nHow does GDP relate to college enrollment?\nHow does Gasoline price relate to GDP?\nIs there any relationship between latitude, longitude and GDP?\nHow closely are CO2 emissions and GDP linked?\n\n\n\n\nLet’s start on the first one,\n\ngdp.vs.college&lt;-ggplot(dataset, mapping = aes(y = GDP, x = Gross.tertiary.education.enrollment...., colour = Country))+\n  geom_point(alpha = 0.8)+\n    xlab(\"Gross College Enrollement\")+\n  ylab(\"GDP(USD)\")+\n  ggtitle(\"GDP and Gross College enrollment across countries\")+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())\ngdp.vs.college&lt;-ggplotly(gdp.vs.college)\ngdp.vs.college\n\n\n\n\n\nSo there’s a problem or two here. These GDP’s have a huge range. Which makes sense, some of these countries have WAY more people that others, what makes sense might be comparing the income per person instead. This is the GDP per capita. From here on out, I’ll use GDP per capita, to account for those passive population differences.\n\ndataset&lt;- dataset |&gt; mutate(GDP.per.capita = round((GDP/Population), 2)) |&gt; na.omit()\ngdp.per.capita.vs.college&lt;-ggplot(dataset, mapping = aes(y = GDP.per.capita, x = Gross.tertiary.education.enrollment...., colour = Country))+\n  geom_point(alpha = 0.8)+\n  geom_smooth(method = \"lm\", se = FALSE)+\n  ggtitle(\"GDP Per capita and College enrollment in various countries\")+\n  xlab(\"Gross College Enrollement\")+\n  ylab(\"GDP per Capita (USD)\")+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())\n  \ngdp.per.capita.vs.college&lt;-ggplotly(gdp.per.capita.vs.college)\ngdp.per.capita.vs.college\n\n\n\n\n\nThis is a little better. While its scattered, and there are definitely outliers, you can definitely see an upward trend. It looks like generally, more college enrollment means more income per person. But it also looks like the more people in college the greater the effect. I suppose it means there’s more people with more knowledge and skills to mix and use to generate income together by collaborating.\n\n\n\n\ngas.vs.gdp.per.capita&lt;-ggplot(dataset, mapping = aes(x = Gasoline.Price, y = GDP.per.capita, colour = Country))+\n  geom_point()+\n  geom_smooth()+\n  xlab(\"Gasoline Prices per litre\")+\n  ylab(\"GDP per Capita (USD)\")+\n  ggtitle('GDP per Capita and Gas Prices Around the World')+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())+\n  scale_x_continuous(labels = label_dollar())\ngas.vs.gdp.per.capita&lt;-ggplotly(gas.vs.gdp.per.capita)\ngas.vs.gdp.per.capita\n\n\n\n\n\nThis relationship is actually a whole lot weaker than I imagined. I wish there was electricity price or some general energy price measure instead. The relationship between gas price and GDP isn’t too strong at all. Which is fine. Sometimes the answer to a question is just “there’s nothing much to see here”.\n\n\n\n\ncord&lt;- dataset |&gt; select(\"Latitude\", \"Longitude\", \"GDP.per.capita\") |&gt;\n  mutate(Latitude = abs(Latitude)) |&gt; mutate(Longitude = abs(Longitude)) |&gt;\n  na.omit()\ncor.matrix&lt;-cor(cord)\nggcorrplot(cor.matrix, type = \"upper\", lab = TRUE)+\n  labs(title = \"Correlation between Latitude, Longitude and GDP per Capita\")\n\n\n\n\nThere’s not quite as much going on in this one. The GDP per capita is kind of correlated to the latitude. But I’ve seen stronger relationships. that number in red shows us that there is something there. The closer it is to 1 and redder that square, the stronger that relationship would be.\n\n\n\nMy question here is whether the CO2 emissions of a country are strongly related to its GDP. If working to produce things for income means more CO2, then it generally follows that countries with a higher GDP should emit more.\nI’ll start off looking graphically. I find its better for intuition.\n\nCO2.vs.gdp.per.capita&lt;-ggplot(dataset, mapping = aes(x = Co2.Emissions, y = GDP.per.capita, colour = Country))+\n  geom_point()+\n  geom_smooth()+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())+\n  labs(title = \"GDP per Capita and CO2 Emissions for various countries\")+\n  xlab(\"CO2 Emissions in tonnes\")+\n  ylab(\"GDP per Capita in USD\")\nCO2.vs.gdp.per.capita&lt;-ggplotly(CO2.vs.gdp.per.capita)\nCO2.vs.gdp.per.capita\n\n\n\n\n\nFrom this graph I can see a few things. Firstly, we have a few massive outliers. If you check the far right, we see China producing tons of CO2, and the US as well. Other countries are producing far less. We also have Liechtenstein, with a very high GDP per capita with pretty low emissions. For the most part though, countries are clustered towards relatively lower emissions.\nThere are a couple ways I can sort through this, I could remove the outliers. China’s huge emissions may just be because of its huge population. I could adjust by seeing what the CO2 per person is.\n\ndataset &lt;- dataset |&gt; mutate(co2.per.capita = Co2.Emissions/Population) |&gt; na.omit()\nco2.gdp.plot&lt;-dataset |&gt; ggplot(mapping = aes(x = co2.per.capita, y = GDP.per.capita, colour = Country))+\n  geom_point()+\n  geom_smooth()+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())+\n  labs(title = \"GDP per Capita and CO2 Emissions per capita for various countries\")+\n  xlab(\"CO2 Emissions per capita in tonnes\")+\n  ylab(\"GDP per Capita in USD\")\n\nco2.gdp.plot&lt;-ggplotly(co2.gdp.plot)\nco2.gdp.plot\n\n\n\n\n\nNow we’re seeing a little more detail. Correcting for the huge difference in populations made a difference. We see a general upward trend, but there are still plenty of outliers, and the relationship could be a lot stronger. There are ways to model and get more info in this relationships, but that’s a topic for later.\n\n\n\nSo, I’ll admit. This should be one of the first steps I took. In trying to put these posts out relatively fast and consistently, I may have rushed the process. There’s a life lesson in there somewhere. I could move this to the top, but I think I’ll leave it here. It will show my actual thought process as I went through this analysis, and be a reminder to go through more methodically next time. In fact, I’ll follow up with this exact data at some point in the future\nThis is a correlation matrix. I’ve used them before in my previous post here and I’m kind of fond of them. Essentially, it’s a graphical way to see how closely related two variables or properties or attributes are. It’s really applicable for numeric data, but on a dataset like this, doing one is invaluable.\n\nnumerics&lt;-dataset |&gt; select_if(is.numeric) |&gt; na.omit()\nnumerics&lt;-cor(numerics)\ngeneral.cor.plot&lt;-ggcorrplot(numerics, hc.order = TRUE, type = \"upper\")+\n  theme(axis.text.x = element_blank(), axis.text.y = element_blank())+\n  labs(title = \"General Correlations\")+\n  theme(plot.title = element_text(hjust = 0.5))\n\ngeneral.cor.plot&lt;-ggplotly(general.cor.plot)\ngeneral.cor.plot\n\n\n\n\n\nThe “redder” the numbers, the more strongly related the variables are. For example two variables which are exactly the same would show up as the reddest. On the flip side, if two variables are related strongly, in opposite directions, they would show up the “Bluest”. These are “Negatively correlated.”\nBecause of how much data there is, I’ve opted to remove the labels and make the graph interactive. If you hover your mouse over a square, you should see the variables that are being compared.\nYou can see 3 clusters of red, showing areas of strongly related variables, and one major blue cluster showing variables which are negatively correlated. And from this there’s so many questions. Each of those clusters represent sets of relationships we could ask about. In fact, you can hover your mouse over the squares to see for yourself.\nJust hovering the mouse over each cluster:\n\nThe bottom red cluster has to do with relationships with “Birth stuff” like birth and fertility rates\nThe middle red cluster has to do with “Population size stuff”, including urban population, army size ect.\nThe top red cluster is more “Income and demographics stuff”, like minimum wage and life expectancy.\nThe blue cluster is “Birth Stuff’, connecting birth stuff to income and life expectancy\n\nSo you’ve seen my process at the moment, and some of the mistakes I’ve made. One day soon, you’ll see me re-attempt. Until next time, walk good.\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22621)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: Etc/GMT+5\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggcorrplot_0.1.4.1 corrplot_0.92      scales_1.2.1       plotly_4.10.2     \n [5] lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0      dplyr_1.1.3       \n [9] purrr_1.0.2        readr_2.1.4        tidyr_1.3.0        tibble_3.2.1      \n[13] ggplot2_3.4.3      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    stringi_1.7.12    hms_1.1.3        \n [5] digest_0.6.33     magrittr_2.0.3    evaluate_0.21     grid_4.3.0       \n [9] timechange_0.2.0  fastmap_1.1.1     plyr_1.8.8        jsonlite_1.8.7   \n[13] httr_1.4.7        fansi_1.0.4       crosstalk_1.2.0   viridisLite_0.4.2\n[17] lazyeval_0.2.2    cli_3.6.1         rlang_1.1.1       ellipsis_0.3.2   \n[21] munsell_0.5.0     withr_2.5.0       yaml_2.3.7        tools_4.3.0      \n[25] reshape2_1.4.4    tzdb_0.4.0        colorspace_2.1-0  vctrs_0.6.3      \n[29] R6_2.5.1          lifecycle_1.0.3   htmlwidgets_1.6.2 pkgconfig_2.0.3  \n[33] pillar_1.9.0      gtable_0.3.4      Rcpp_1.0.11       glue_1.6.2       \n[37] data.table_1.14.8 xfun_0.40         tidyselect_1.2.0  rstudioapi_0.15.0\n[41] knitr_1.44        farver_2.1.1      htmltools_0.5.6   rmarkdown_2.25   \n[45] labeling_0.4.3    compiler_4.3.0"
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#re-formatting",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#re-formatting",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "Cleaning 35 columns now, saves me a lot of heartache in the future. I won’t show it all but here are some examples of how I could do that.\n\ndataset&lt;- dataset |&gt; mutate (GDP = GDP |&gt; str_remove_all(\"[$,]\") |&gt; as.numeric())\ndataset$Density..P.Km2.&lt;-as.numeric(dataset$Density..P.Km2.)\n\nThankfully, there are more efficient ways to work\n\nc.names&lt;-colnames(dataset)\ncols.to.format&lt;-c.names[-c(1,3, 9, 13, 21, 25)]\ncols.that.can.stay&lt;-c.names[c(1,3, 9, 13, 21, 25)]\ndataset&lt;-dataset |&gt; \n  mutate(across(.cols = cols.to.format,.fns = ~str_remove_all(.x, \"[$,%]\")|&gt; \n                  as.numeric()))\n\nWhat I’ve done above is to convert all the relevant character or text fields/columns into numbers so I can work with them."
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#what-do-we-want-to-know",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#what-do-we-want-to-know",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "Now comes the brainstorming. There’s a lot of data here. A lot of the questions that come to mind have to do with GDP. GDP, the gross domestic product, is essentially the dollar value of all the “Stuff” bought and sold in a country. You could also look at it as the country’s income. It’s not a perfect measure, but it can be useful. At the very least it gives me some questions to ask.\nThe questions that pop out to me are:\n\nHow does GDP relate to college enrollment?\nHow does Gasoline price relate to GDP?\nIs there any relationship between latitude, longitude and GDP?\nHow closely are CO2 emissions and GDP linked?"
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#how-does-gdp-relate-to-college-enrollment",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#how-does-gdp-relate-to-college-enrollment",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "Let’s start on the first one,\n\ngdp.vs.college&lt;-ggplot(dataset, mapping = aes(y = GDP, x = Gross.tertiary.education.enrollment...., colour = Country))+\n  geom_point(alpha = 0.8)+\n    xlab(\"Gross College Enrollement\")+\n  ylab(\"GDP(USD)\")+\n  ggtitle(\"GDP and Gross College enrollment across countries\")+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())\ngdp.vs.college&lt;-ggplotly(gdp.vs.college)\ngdp.vs.college\n\n\n\n\n\nSo there’s a problem or two here. These GDP’s have a huge range. Which makes sense, some of these countries have WAY more people that others, what makes sense might be comparing the income per person instead. This is the GDP per capita. From here on out, I’ll use GDP per capita, to account for those passive population differences.\n\ndataset&lt;- dataset |&gt; mutate(GDP.per.capita = round((GDP/Population), 2)) |&gt; na.omit()\ngdp.per.capita.vs.college&lt;-ggplot(dataset, mapping = aes(y = GDP.per.capita, x = Gross.tertiary.education.enrollment...., colour = Country))+\n  geom_point(alpha = 0.8)+\n  geom_smooth(method = \"lm\", se = FALSE)+\n  ggtitle(\"GDP Per capita and College enrollment in various countries\")+\n  xlab(\"Gross College Enrollement\")+\n  ylab(\"GDP per Capita (USD)\")+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())\n  \ngdp.per.capita.vs.college&lt;-ggplotly(gdp.per.capita.vs.college)\ngdp.per.capita.vs.college\n\n\n\n\n\nThis is a little better. While its scattered, and there are definitely outliers, you can definitely see an upward trend. It looks like generally, more college enrollment means more income per person. But it also looks like the more people in college the greater the effect. I suppose it means there’s more people with more knowledge and skills to mix and use to generate income together by collaborating."
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#gas-prices-and-gdp",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#gas-prices-and-gdp",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "gas.vs.gdp.per.capita&lt;-ggplot(dataset, mapping = aes(x = Gasoline.Price, y = GDP.per.capita, colour = Country))+\n  geom_point()+\n  geom_smooth()+\n  xlab(\"Gasoline Prices per litre\")+\n  ylab(\"GDP per Capita (USD)\")+\n  ggtitle('GDP per Capita and Gas Prices Around the World')+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())+\n  scale_x_continuous(labels = label_dollar())\ngas.vs.gdp.per.capita&lt;-ggplotly(gas.vs.gdp.per.capita)\ngas.vs.gdp.per.capita\n\n\n\n\n\nThis relationship is actually a whole lot weaker than I imagined. I wish there was electricity price or some general energy price measure instead. The relationship between gas price and GDP isn’t too strong at all. Which is fine. Sometimes the answer to a question is just “there’s nothing much to see here”."
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#latitude-longitude-and-gdp",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#latitude-longitude-and-gdp",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "cord&lt;- dataset |&gt; select(\"Latitude\", \"Longitude\", \"GDP.per.capita\") |&gt;\n  mutate(Latitude = abs(Latitude)) |&gt; mutate(Longitude = abs(Longitude)) |&gt;\n  na.omit()\ncor.matrix&lt;-cor(cord)\nggcorrplot(cor.matrix, type = \"upper\", lab = TRUE)+\n  labs(title = \"Correlation between Latitude, Longitude and GDP per Capita\")\n\n\n\n\nThere’s not quite as much going on in this one. The GDP per capita is kind of correlated to the latitude. But I’ve seen stronger relationships. that number in red shows us that there is something there. The closer it is to 1 and redder that square, the stronger that relationship would be."
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#co2-and-gdp",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#co2-and-gdp",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "My question here is whether the CO2 emissions of a country are strongly related to its GDP. If working to produce things for income means more CO2, then it generally follows that countries with a higher GDP should emit more.\nI’ll start off looking graphically. I find its better for intuition.\n\nCO2.vs.gdp.per.capita&lt;-ggplot(dataset, mapping = aes(x = Co2.Emissions, y = GDP.per.capita, colour = Country))+\n  geom_point()+\n  geom_smooth()+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())+\n  labs(title = \"GDP per Capita and CO2 Emissions for various countries\")+\n  xlab(\"CO2 Emissions in tonnes\")+\n  ylab(\"GDP per Capita in USD\")\nCO2.vs.gdp.per.capita&lt;-ggplotly(CO2.vs.gdp.per.capita)\nCO2.vs.gdp.per.capita\n\n\n\n\n\nFrom this graph I can see a few things. Firstly, we have a few massive outliers. If you check the far right, we see China producing tons of CO2, and the US as well. Other countries are producing far less. We also have Liechtenstein, with a very high GDP per capita with pretty low emissions. For the most part though, countries are clustered towards relatively lower emissions.\nThere are a couple ways I can sort through this, I could remove the outliers. China’s huge emissions may just be because of its huge population. I could adjust by seeing what the CO2 per person is.\n\ndataset &lt;- dataset |&gt; mutate(co2.per.capita = Co2.Emissions/Population) |&gt; na.omit()\nco2.gdp.plot&lt;-dataset |&gt; ggplot(mapping = aes(x = co2.per.capita, y = GDP.per.capita, colour = Country))+\n  geom_point()+\n  geom_smooth()+\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")+\n  scale_y_continuous(labels = label_dollar())+\n  labs(title = \"GDP per Capita and CO2 Emissions per capita for various countries\")+\n  xlab(\"CO2 Emissions per capita in tonnes\")+\n  ylab(\"GDP per Capita in USD\")\n\nco2.gdp.plot&lt;-ggplotly(co2.gdp.plot)\nco2.gdp.plot\n\n\n\n\n\nNow we’re seeing a little more detail. Correcting for the huge difference in populations made a difference. We see a general upward trend, but there are still plenty of outliers, and the relationship could be a lot stronger. There are ways to model and get more info in this relationships, but that’s a topic for later."
  },
  {
    "objectID": "docs/posts/1st World Data Analysis/WorldData.html#general-correlation",
    "href": "docs/posts/1st World Data Analysis/WorldData.html#general-correlation",
    "title": "1st Attempt at Analysing World Data",
    "section": "",
    "text": "So, I’ll admit. This should be one of the first steps I took. In trying to put these posts out relatively fast and consistently, I may have rushed the process. There’s a life lesson in there somewhere. I could move this to the top, but I think I’ll leave it here. It will show my actual thought process as I went through this analysis, and be a reminder to go through more methodically next time. In fact, I’ll follow up with this exact data at some point in the future\nThis is a correlation matrix. I’ve used them before in my previous post here and I’m kind of fond of them. Essentially, it’s a graphical way to see how closely related two variables or properties or attributes are. It’s really applicable for numeric data, but on a dataset like this, doing one is invaluable.\n\nnumerics&lt;-dataset |&gt; select_if(is.numeric) |&gt; na.omit()\nnumerics&lt;-cor(numerics)\ngeneral.cor.plot&lt;-ggcorrplot(numerics, hc.order = TRUE, type = \"upper\")+\n  theme(axis.text.x = element_blank(), axis.text.y = element_blank())+\n  labs(title = \"General Correlations\")+\n  theme(plot.title = element_text(hjust = 0.5))\n\ngeneral.cor.plot&lt;-ggplotly(general.cor.plot)\ngeneral.cor.plot\n\n\n\n\n\nThe “redder” the numbers, the more strongly related the variables are. For example two variables which are exactly the same would show up as the reddest. On the flip side, if two variables are related strongly, in opposite directions, they would show up the “Bluest”. These are “Negatively correlated.”\nBecause of how much data there is, I’ve opted to remove the labels and make the graph interactive. If you hover your mouse over a square, you should see the variables that are being compared.\nYou can see 3 clusters of red, showing areas of strongly related variables, and one major blue cluster showing variables which are negatively correlated. And from this there’s so many questions. Each of those clusters represent sets of relationships we could ask about. In fact, you can hover your mouse over the squares to see for yourself.\nJust hovering the mouse over each cluster:\n\nThe bottom red cluster has to do with relationships with “Birth stuff” like birth and fertility rates\nThe middle red cluster has to do with “Population size stuff”, including urban population, army size ect.\nThe top red cluster is more “Income and demographics stuff”, like minimum wage and life expectancy.\nThe blue cluster is “Birth Stuff’, connecting birth stuff to income and life expectancy\n\nSo you’ve seen my process at the moment, and some of the mistakes I’ve made. One day soon, you’ll see me re-attempt. Until next time, walk good.\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22621)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: Etc/GMT+5\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggcorrplot_0.1.4.1 corrplot_0.92      scales_1.2.1       plotly_4.10.2     \n [5] lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0      dplyr_1.1.3       \n [9] purrr_1.0.2        readr_2.1.4        tidyr_1.3.0        tibble_3.2.1      \n[13] ggplot2_3.4.3      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    stringi_1.7.12    hms_1.1.3        \n [5] digest_0.6.33     magrittr_2.0.3    evaluate_0.21     grid_4.3.0       \n [9] timechange_0.2.0  fastmap_1.1.1     plyr_1.8.8        jsonlite_1.8.7   \n[13] httr_1.4.7        fansi_1.0.4       crosstalk_1.2.0   viridisLite_0.4.2\n[17] lazyeval_0.2.2    cli_3.6.1         rlang_1.1.1       ellipsis_0.3.2   \n[21] munsell_0.5.0     withr_2.5.0       yaml_2.3.7        tools_4.3.0      \n[25] reshape2_1.4.4    tzdb_0.4.0        colorspace_2.1-0  vctrs_0.6.3      \n[29] R6_2.5.1          lifecycle_1.0.3   htmlwidgets_1.6.2 pkgconfig_2.0.3  \n[33] pillar_1.9.0      gtable_0.3.4      Rcpp_1.0.11       glue_1.6.2       \n[37] data.table_1.14.8 xfun_0.40         tidyselect_1.2.0  rstudioapi_0.15.0\n[41] knitr_1.44        farver_2.1.1      htmltools_0.5.6   rmarkdown_2.25   \n[45] labeling_0.4.3    compiler_4.3.0"
  }
]